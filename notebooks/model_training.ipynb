{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b952465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Model Training Notebook for Tech Book Recommender\n",
    "# Save this as: notebooks/model_training.ipynb\n",
    "\n",
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5569213b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 25 books\n",
      "   book_id                                              title  \\\n",
      "0        1  Hands-On Machine Learning with Scikit-Learn, K...   \n",
      "1        2                                      Deep Learning   \n",
      "2        3                            Python Machine Learning   \n",
      "3        4            Reinforcement Learning: An Introduction   \n",
      "4        5           Pattern Recognition and Machine Learning   \n",
      "\n",
      "                                           author                category  \\\n",
      "0                                  Aurélien Géron        Machine Learning   \n",
      "1  Ian Goodfellow, Yoshua Bengio, Aaron Courville           Deep Learning   \n",
      "2                               Sebastian Raschka        Machine Learning   \n",
      "3              Richard S. Sutton, Andrew G. Barto  Reinforcement Learning   \n",
      "4                           Christopher M. Bishop        Machine Learning   \n",
      "\n",
      "          level  rating  year  \n",
      "0  Intermediate     4.6  2022  \n",
      "1      Advanced     4.5  2016  \n",
      "2  Intermediate     4.4  2019  \n",
      "3      Advanced     4.7  2018  \n",
      "4      Advanced     4.6  2006  \n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Load Data\n",
    "books_data = {\n",
    "    'book_id': range(1, 26),\n",
    "    'title': [\n",
    "        \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\",\n",
    "        \"Deep Learning\", \"Python Machine Learning\", \n",
    "        \"Reinforcement Learning: An Introduction\",\n",
    "        \"Pattern Recognition and Machine Learning\",\n",
    "        \"Deep Learning with Python\", \"The Hundred-Page Machine Learning Book\",\n",
    "        \"Python for Data Analysis\", \"Introduction to Statistical Learning\",\n",
    "        \"Natural Language Processing with Python\",\n",
    "        \"Computer Vision: Algorithms and Applications\",\n",
    "        \"Designing Machine Learning Systems\", \"Grokking Deep Learning\",\n",
    "        \"Data Science from Scratch\", \"Algorithms\",\n",
    "        \"Deep Reinforcement Learning Hands-On\", \"Fluent Python\",\n",
    "        \"Speech and Language Processing\", \"Machine Learning Engineering\",\n",
    "        \"Probabilistic Machine Learning: An Introduction\",\n",
    "        \"Deep Learning for Computer Vision\", \"Python Data Science Handbook\",\n",
    "        \"Introduction to Algorithms\", \"Effective Python\",\n",
    "        \"Neural Networks and Deep Learning\"\n",
    "    ],\n",
    "    'author': [\n",
    "        \"Aurélien Géron\", \"Ian Goodfellow, Yoshua Bengio, Aaron Courville\",\n",
    "        \"Sebastian Raschka\", \"Richard S. Sutton, Andrew G. Barto\",\n",
    "        \"Christopher M. Bishop\", \"François Chollet\", \"Andriy Burkov\",\n",
    "        \"Wes McKinney\", \"Gareth James, Daniela Witten\", \"Steven Bird, Ewan Klein\",\n",
    "        \"Richard Szeliski\", \"Chip Huyen\", \"Andrew Trask\", \"Joel Grus\",\n",
    "        \"Robert Sedgewick, Kevin Wayne\", \"Maxim Lapan\", \"Luciano Ramalho\",\n",
    "        \"Dan Jurafsky, James H. Martin\", \"Andriy Burkov\", \"Kevin Murphy\",\n",
    "        \"Rajalingappaa Shanmugamani\", \"Jake VanderPlas\", \"Thomas H. Cormen\",\n",
    "        \"Brett Slatkin\", \"Michael Nielsen\"\n",
    "    ],\n",
    "    'category': [\n",
    "        \"Machine Learning\", \"Deep Learning\", \"Machine Learning\", \n",
    "        \"Reinforcement Learning\", \"Machine Learning\", \"Deep Learning\",\n",
    "        \"Machine Learning\", \"Data Science\", \"Machine Learning\", \"NLP\",\n",
    "        \"Computer Vision\", \"MLOps\", \"Deep Learning\", \"Data Science\", \"Algorithms\",\n",
    "        \"Reinforcement Learning\", \"Python\", \"NLP\", \"MLOps\", \"Machine Learning\",\n",
    "        \"Computer Vision\", \"Data Science\", \"Algorithms\", \"Python\", \"Deep Learning\"\n",
    "    ],\n",
    "    'level': [\n",
    "        \"Intermediate\", \"Advanced\", \"Intermediate\", \"Advanced\", \"Advanced\",\n",
    "        \"Beginner\", \"Beginner\", \"Beginner\", \"Intermediate\", \"Intermediate\",\n",
    "        \"Advanced\", \"Intermediate\", \"Beginner\", \"Beginner\", \"Intermediate\",\n",
    "        \"Intermediate\", \"Intermediate\", \"Advanced\", \"Intermediate\", \"Advanced\",\n",
    "        \"Intermediate\", \"Intermediate\", \"Advanced\", \"Intermediate\", \"Beginner\"\n",
    "    ],\n",
    "    'rating': [4.6, 4.5, 4.4, 4.7, 4.6, 4.5, 4.3, 4.4, 4.6, 4.2, 4.5, 4.7, \n",
    "               4.4, 4.3, 4.5, 4.4, 4.7, 4.6, 4.5, 4.6, 4.3, 4.5, 4.5, 4.5, 4.7],\n",
    "    'year': [2022, 2016, 2019, 2018, 2006, 2021, 2019, 2022, 2021, 2009, \n",
    "             2022, 2022, 2019, 2019, 2011, 2020, 2022, 2023, 2020, 2022, \n",
    "             2018, 2016, 2009, 2019, 2015]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(books_data)\n",
    "print(f\"✓ Loaded {len(df)} books\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "255cc30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "FEATURE ENGINEERING\n",
      "============================================================\n",
      "✓ Features engineered\n",
      "   book_id                                              title  \\\n",
      "0        1  Hands-On Machine Learning with Scikit-Learn, K...   \n",
      "1        2                                      Deep Learning   \n",
      "2        3                            Python Machine Learning   \n",
      "3        4            Reinforcement Learning: An Introduction   \n",
      "4        5           Pattern Recognition and Machine Learning   \n",
      "\n",
      "   category_encoded  level_encoded  year_normalized  \n",
      "0                 5              2         0.941176  \n",
      "1                 3              0         0.588235  \n",
      "2                 5              2         0.764706  \n",
      "3                 8              0         0.705882  \n",
      "4                 5              0         0.000000  \n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Feature Engineering\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE ENGINEERING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create content features\n",
    "df['content'] = df['title'] + ' ' + df['category'] + ' ' + df['level'] + ' ' + df['author']\n",
    "\n",
    "# Encode categorical variables\n",
    "le_category = LabelEncoder()\n",
    "le_level = LabelEncoder()\n",
    "\n",
    "df['category_encoded'] = le_category.fit_transform(df['category'])\n",
    "df['level_encoded'] = le_level.fit_transform(df['level'])\n",
    "\n",
    "# Normalize year\n",
    "df['year_normalized'] = (df['year'] - df['year'].min()) / (df['year'].max() - df['year'].min())\n",
    "\n",
    "print(\"✓ Features engineered\")\n",
    "print(df[['book_id', 'title', 'category_encoded', 'level_encoded', 'year_normalized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf954ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING CONTENT-BASED MODEL\n",
      "============================================================\n",
      "TF-IDF Matrix Shape: (25, 100)\n",
      "Number of features: 100\n",
      "Cosine Similarity Matrix Shape: (25, 25)\n",
      "\n",
      "Recommendations for book ID 1 (Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow):\n",
      "    book_id                                            title  \\\n",
      "2         3                          Python Machine Learning   \n",
      "19       20  Probabilistic Machine Learning: An Introduction   \n",
      "6         7           The Hundred-Page Machine Learning Book   \n",
      "\n",
      "            category  rating  \n",
      "2   Machine Learning     4.4  \n",
      "19  Machine Learning     4.6  \n",
      "6   Machine Learning     4.3  \n",
      "\n",
      "✓ Content-based model trained\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Train Content-Based Model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING CONTENT-BASED MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=100)\n",
    "tfidf_matrix = tfidf.fit_transform(df['content'])\n",
    "\n",
    "print(f\"TF-IDF Matrix Shape: {tfidf_matrix.shape}\")\n",
    "print(f\"Number of features: {len(tfidf.get_feature_names_out())}\")\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(f\"Cosine Similarity Matrix Shape: {cosine_sim.shape}\")\n",
    "\n",
    "# Test the model\n",
    "def get_content_recommendations(book_id, n=5):\n",
    "    idx = df[df['book_id'] == book_id].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:n+1]  # Exclude the book itself\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    return df.iloc[book_indices][['book_id', 'title', 'category', 'rating']]\n",
    "\n",
    "# Test\n",
    "test_book_id = 1\n",
    "print(f\"\\nRecommendations for book ID {test_book_id} ({df[df['book_id']==test_book_id]['title'].values[0]}):\")\n",
    "print(get_content_recommendations(test_book_id, n=3))\n",
    "\n",
    "print(\"\\n✓ Content-based model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0baa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING KNN MODEL\n",
      "============================================================\n",
      "Feature Matrix Shape: (25, 4)\n",
      "\n",
      "KNN Recommendations for book ID 1:\n",
      "    book_id                                 title          category  rating\n",
      "8         9  Introduction to Statistical Learning  Machine Learning     4.6\n",
      "2         3               Python Machine Learning  Machine Learning     4.4\n",
      "18       19          Machine Learning Engineering             MLOps     4.5\n",
      "\n",
      "✓ KNN model trained\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Train KNN Model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING KNN MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create feature matrix\n",
    "feature_matrix = df[['category_encoded', 'level_encoded', 'rating', 'year_normalized']].values\n",
    "\n",
    "# Train KNN\n",
    "knn = NearestNeighbors(n_neighbors=6, metric='cosine')\n",
    "knn.fit(feature_matrix)\n",
    "\n",
    "print(f\"Feature Matrix Shape: {feature_matrix.shape}\")\n",
    "\n",
    "# Test KNN\n",
    "def get_knn_recommendations(book_id, n=5):\n",
    "    idx = df[df['book_id'] == book_id].index[0]\n",
    "    book_features = feature_matrix[idx].reshape(1, -1)\n",
    "    distances, indices = knn.kneighbors(book_features, n_neighbors=n+1)\n",
    "    similar_indices = indices[0][1:]  # Exclude the book itself\n",
    "    return df.iloc[similar_indices][['book_id', 'title', 'category', 'rating']]\n",
    "\n",
    "# Test\n",
    "print(f\"\\nKNN Recommendations for book ID {test_book_id}:\")\n",
    "print(get_knn_recommendations(test_book_id, n=3))\n",
    "\n",
    "print(\"\\n✓ KNN model trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c5176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING HYBRID RECOMMENDER\n",
      "============================================================\n",
      "\n",
      "Hybrid Recommendations for user ratings: {1: 5, 3: 4, 6: 5}\n",
      "    book_id                                            title  \\\n",
      "4         5         Pattern Recognition and Machine Learning   \n",
      "6         7           The Hundred-Page Machine Learning Book   \n",
      "8         9             Introduction to Statistical Learning   \n",
      "15       16             Deep Reinforcement Learning Hands-On   \n",
      "19       20  Probabilistic Machine Learning: An Introduction   \n",
      "\n",
      "                  category  rating  \n",
      "4         Machine Learning     4.6  \n",
      "6         Machine Learning     4.3  \n",
      "8         Machine Learning     4.6  \n",
      "15  Reinforcement Learning     4.4  \n",
      "19        Machine Learning     4.6  \n",
      "\n",
      "✓ Hybrid recommender created\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Hybrid Recommendation Function\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING HYBRID RECOMMENDER\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def hybrid_recommend(user_ratings, n=6):\n",
    "    \"\"\"\n",
    "    Hybrid recommendation combining content-based and KNN\n",
    "    user_ratings: dict {book_id: rating}\n",
    "    \"\"\"\n",
    "    # Get highly rated books\n",
    "    liked_books = [book_id for book_id, rating in user_ratings.items() if rating >= 4]\n",
    "    \n",
    "    if not liked_books:\n",
    "        # Return popular books if no high ratings\n",
    "        return df.nlargest(n, 'rating')[['book_id', 'title', 'category', 'rating']]\n",
    "    \n",
    "    # Get content-based recommendations\n",
    "    content_recs = []\n",
    "    for book_id in liked_books:\n",
    "        content_recs.extend(get_content_recommendations(book_id, n=5)['book_id'].tolist())\n",
    "    \n",
    "    # Get KNN recommendations\n",
    "    knn_recs = []\n",
    "    for book_id in liked_books[:3]:  # Use top 3 liked books\n",
    "        knn_recs.extend(get_knn_recommendations(book_id, n=5)['book_id'].tolist())\n",
    "    \n",
    "    # Combine and score\n",
    "    all_recs = {}\n",
    "    for book_id in content_recs:\n",
    "        all_recs[book_id] = all_recs.get(book_id, 0) + 0.5  # Content weight\n",
    "    \n",
    "    for book_id in knn_recs:\n",
    "        all_recs[book_id] = all_recs.get(book_id, 0) + 0.3  # KNN weight\n",
    "    \n",
    "    # Add popularity score\n",
    "    for book_id in all_recs.keys():\n",
    "        book = df[df['book_id'] == book_id]\n",
    "        if not book.empty:\n",
    "            all_recs[book_id] += book.iloc[0]['rating'] * 0.2\n",
    "    \n",
    "    # Remove already rated books\n",
    "    for book_id in user_ratings.keys():\n",
    "        all_recs.pop(book_id, None)\n",
    "    \n",
    "    # Sort and return top N\n",
    "    sorted_recs = sorted(all_recs.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "    rec_ids = [book_id for book_id, _ in sorted_recs]\n",
    "    \n",
    "    return df[df['book_id'].isin(rec_ids)][['book_id', 'title', 'category', 'rating']]\n",
    "\n",
    "# Test hybrid model\n",
    "test_ratings = {1: 5, 3: 4, 6: 5}\n",
    "print(f\"\\nHybrid Recommendations for user ratings: {test_ratings}\")\n",
    "print(hybrid_recommend(test_ratings, n=5))\n",
    "\n",
    "print(\"\\n✓ Hybrid recommender created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e172ae22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL EVALUATION\n",
      "============================================================\n",
      "   user_id  num_ratings  avg_user_rating  avg_rec_rating\n",
      "0        0            6         4.000000            4.44\n",
      "1        1            4         4.500000            4.44\n",
      "2        2            3         3.000000            4.68\n",
      "3        3            7         4.428571            4.54\n",
      "4        4            5         4.200000            4.54\n",
      "\n",
      "Average Recommendation Quality: 4.53\n",
      "\n",
      "✓ Model evaluation complete\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Model Evaluation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Simulate user ratings for testing\n",
    "np.random.seed(42)\n",
    "test_users = 5\n",
    "evaluation_results = []\n",
    "\n",
    "for user_id in range(test_users):\n",
    "    # Random user ratings\n",
    "    num_ratings = np.random.randint(3, 8)\n",
    "    rated_books = np.random.choice(df['book_id'].values, size=num_ratings, replace=False)\n",
    "    user_ratings = {book_id: np.random.randint(3, 6) for book_id in rated_books}\n",
    "    \n",
    "    # Get recommendations\n",
    "    recommendations = hybrid_recommend(user_ratings, n=5)\n",
    "    \n",
    "    # Calculate average rating of recommendations\n",
    "    avg_rec_rating = recommendations['rating'].mean()\n",
    "    \n",
    "    evaluation_results.append({\n",
    "        'user_id': user_id,\n",
    "        'num_ratings': num_ratings,\n",
    "        'avg_user_rating': np.mean(list(user_ratings.values())),\n",
    "        'avg_rec_rating': avg_rec_rating\n",
    "    })\n",
    "\n",
    "eval_df = pd.DataFrame(evaluation_results)\n",
    "print(eval_df)\n",
    "print(f\"\\nAverage Recommendation Quality: {eval_df['avg_rec_rating'].mean():.2f}\")\n",
    "\n",
    "print(\"\\n✓ Model evaluation complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "614cb273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SAVING MODELS\n",
      "============================================================\n",
      "✓ Content-based model saved\n",
      "✓ KNN model saved\n",
      "✓ Label encoders saved\n",
      "\n",
      "============================================================\n",
      "MODEL TRAINING COMPLETE!\n",
      "============================================================\n",
      "\n",
      "Saved files:\n",
      "  - models/content_based_model.pkl\n",
      "  - models/knn_model.pkl\n",
      "  - models/label_encoders.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save Models\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Save content-based model\n",
    "content_model = {\n",
    "    'tfidf': tfidf,\n",
    "    'tfidf_matrix': tfidf_matrix,\n",
    "    'cosine_sim': cosine_sim,\n",
    "    'books_df': df\n",
    "}\n",
    "\n",
    "with open('../models/content_based_model.pkl', 'wb') as f:\n",
    "    pickle.dump(content_model, f)\n",
    "print(\"✓ Content-based model saved\")\n",
    "\n",
    "# Save KNN model\n",
    "knn_model = {\n",
    "    'knn': knn,\n",
    "    'feature_matrix': feature_matrix,\n",
    "    'books_df': df,\n",
    "    'le_category': le_category,\n",
    "    'le_level': le_level\n",
    "}\n",
    "\n",
    "with open('../models/knn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(knn_model, f)\n",
    "print(\"✓ KNN model saved\")\n",
    "\n",
    "# Save encoders\n",
    "with open('../models/label_encoders.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'category': le_category,\n",
    "        'level': le_level\n",
    "    }, f)\n",
    "print(\"✓ Label encoders saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL TRAINING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"  - models/content_based_model.pkl\")\n",
    "print(\"  - models/knn_model.pkl\")\n",
    "print(\"  - models/label_encoders.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
